{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4693afca-f449-4358-a861-41f5830b87ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import wfdb\n",
    "import chorus_converter.utils as wfdb_conv_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b121db-2530-493f-ac58-06aee494b469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals: Things to parameterize:\n",
    "\n",
    "# Column name used for timing.\n",
    "wfdb_conv_funcs.TIMING_COL = 'time'\n",
    "\n",
    "# Column name used for the converted timestamp index.\n",
    "wfdb_conv_funcs.TIMING_INDEX_COL = 'Timestamp'\n",
    "\n",
    "# The expected units of the timing column (string must be compatible with np.datetime64).\n",
    "wfdb_conv_funcs.EXPECTED_TIMING_UNITS = 'ns'\n",
    "\n",
    "# Set the maximum segment length, in seconds. (Here: 8hrs * 60mins/hr * 60seconds/min)\n",
    "wfdb_conv_funcs.MAX_SEGMENT_LENGTH_SECONDS = 8*60*60\n",
    "\n",
    "# Set the format for the WFDB files.\n",
    "wfdb_conv_funcs.BINARY_FMT = ['16']\n",
    "\n",
    "# Set the acceptable tolerance in the measured vs. expected sampling frequencies.\n",
    "wfdb_conv_funcs.HZ_TOLERANCE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c626ceaf-ca0d-415a-a034-835e86e1d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directory where the test Sickbay waveforms live.\n",
    "base_wf_dir = ''\n",
    "sickbay_mapping_file = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e130a2-2197-40fe-951a-3a875d686441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For CHoRUS would need to come up with a dictionary that maps each sites channels to some common names.\n",
    "sickbay_fast_lookup_df = wfdb_conv_funcs.get_duke_mapping_df(base_wf_dir, sickbay_mapping_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a37ed7-ebdd-4f0d-9682-0ff09c462d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How would we get the start datetime from Sickbay? Lets assume a simply solution and have it temporarily saved in the filename.\n",
    "\n",
    "# Example file naming:\n",
    "# {SickbayID}_{YYYYMMDD}_{HHMMSS}.csv\n",
    "\n",
    "input_filename = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e420be-8604-4716-a07b-52b5034299bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read an example WF file, extracting some metadata and the signals. \n",
    "input_file_ID, input_date, input_time, signal_df = wfdb_conv_funcs.read_duke_wf(base_wf_dir, input_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fce2c5-872d-40d8-a5e1-a3fc11621e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of the channels present in the data.\n",
    "channel_cols = wfdb_conv_funcs.get_channel_cols(signal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e725882d-1eac-473d-a030-62de0b578ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the mapping file to extract more metadata for the channels in this WF file.\n",
    "sig_names_dict, samp_freqs_dict, units_dict = wfdb_conv_funcs.get_signal_meta_dicts(channel_cols, sickbay_fast_lookup_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375001fe-b071-4204-b087-2334b031ccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want the same binarized format for all channels, expand the list to match the number of channels.\n",
    "fmt = wfdb_conv_funcs.BINARY_FMT * len(channel_cols) # [wfdb.io.Record PARAM]\n",
    "\n",
    "# Set the WFDB 'units' variable to our list of units.\n",
    "units = list(units_dict.values()) # [wfdb.io.Record PARAM]\n",
    "\n",
    "# Set the WFDB 'sig_name' variable to our list of signal names.\n",
    "sig_names_list = list(sig_names_dict.values()) # [wfdb.io.Record PARAM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039e497f-869c-4314-8da4-320bc6f85da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the expected sampling frequency, from the mapping file, for the available channels.\n",
    "expected_fs = int(max(list(samp_freqs_dict.values()))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3142c40-a781-4c50-a6c7-23ce76f268ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the inter-sample timing for the data and make sure it's within bounds of the expected sampling frequency.\n",
    "fs = wfdb_conv_funcs.check_timing_coherancy(signal_df, expected_fs, wfdb_conv_funcs.HZ_TOLERANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ea0972-0e76-47e0-84a5-dce84d76f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a DateTime index to the signal dataframe. \n",
    "base_date, base_time = wfdb_conv_funcs.add_timing_index(signal_df, input_date, input_time, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be91c51-a6da-4da0-8e8c-f53bf2ee5c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some of the rows to all NaNs for testing (note the use of loc vs. iloc here, hence the -1 on the indexing as loc is INCLUSIVE!):\n",
    "signal_df.loc[500_000:600_000-1, channel_cols] = np.nan\n",
    "signal_df.loc[10_000_000:11_000_000-1, channel_cols] = np.nan\n",
    "signal_df.loc[15_000_000:16_000_000-1, channel_cols] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde12f9-5d8c-437d-a732-84f8683a0c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for chunks of missing data in the signal matrix and mark when the data starts and stops.\n",
    "data_block_start_indices, NaN_block_start_indices = wfdb_conv_funcs.check_missing_data_blocks(signal_df, channel_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd31e48-82d9-4a1b-8a20-dedf8c366df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that all segments won't exceed the max file length we'd like to stick to.\n",
    "segment_start_indices, segment_stop_indices = wfdb_conv_funcs.check_oversized_chunks(data_block_start_indices, NaN_block_start_indices, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c8b618-b837-4d04-a70c-3d7ca5010d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the record name, here we use the Sickbay ID.\n",
    "master_record_name = input_file_ID # [wfdb.io.Record PARAM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390c7812-84ac-467b-b3cc-2360765f1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the segments and gather the segment-specific metadata.\n",
    "(\n",
    "segment_record_names_list, \n",
    "data_segment_start_times_list, \n",
    "data_segment_list, \n",
    "segment_channels_list\n",
    ") = wfdb_conv_funcs.prepare_segment_data(\n",
    "    signal_df=signal_df, \n",
    "    channel_cols=channel_cols, \n",
    "    master_record_name=master_record_name, \n",
    "    segment_start_indices=segment_start_indices, \n",
    "    segment_stop_indices=segment_stop_indices,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5279b69b-9c76-4cc2-8a61-43e25d92a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the individual records for each segment.\n",
    "segments_record_list = wfdb_conv_funcs.create_segment_records(\n",
    "    segment_record_names_list=segment_record_names_list, \n",
    "    data_segment_start_times_list=data_segment_start_times_list, \n",
    "    data_segment_list=data_segment_list, \n",
    "    segment_channels_list=segment_channels_list, \n",
    "    units_dict=units_dict, \n",
    "    sig_names_dict=sig_names_dict, \n",
    "    fs=fs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfc40df-b4d3-49f4-95e8-18fea90f9e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the segment records/metadata together with the overall metadata for the multi-segment record.\n",
    "sickbay_multirecord = wfdb_conv_funcs.create_multirecord(\n",
    "    segments_record_list=segments_record_list, \n",
    "    master_record_name=master_record_name,\n",
    "    segment_record_names_list=segment_record_names_list, \n",
    "    data_segment_start_times_list=data_segment_start_times_list, \n",
    "    channel_cols=channel_cols, \n",
    "    sig_names_list=sig_names_list, \n",
    "    units=units, \n",
    "    fs=fs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4aceb4-6a0b-464b-b30a-7bd2484d4a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to add '~' for the empty segments in 'seg_name'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9c91a5-b9e5-428b-aff8-1392b5c24211",
   "metadata": {},
   "outputs": [],
   "source": [
    "sickbay_multirecord.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a124b2b2-4cd8-4f19-b413-dee6ab7391f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the Record (the WFDB header file(s) and any associated dat files from this object) to disk.\n",
    "sickbay_multirecord.wrsamp(write_dir=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CHoRUS (Py3.11)",
   "language": "python",
   "name": "chorus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
